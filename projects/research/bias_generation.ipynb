{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTALLS THAT NEED TO BE RUN ON CONDA\n",
    "# !pip install loguru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import base64\n",
    "import re\n",
    "import os\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import time\n",
    "from importlib import reload\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from io import BytesIO\n",
    "from botocore.config import Config\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, force=True)  # Resets handlers\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# os.chdir('..')\n",
    "print(\"CWD:\", os.getcwd())\n",
    "bedrock_runtime = boto3.client(\"bedrock-runtime\")\n",
    "s3 = boto3.client(\"s3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.chdir(\"../../lib/src\")\n",
    "    import image_captioning_assistant.generate.prompts as p\n",
    "    import image_captioning_assistant.data.data_classes as dc\n",
    "    \n",
    "    # current\n",
    "    import image_captioning_assistant.generate.bias_analysis.find_biases_in_short_work as gbsw\n",
    "    import image_captioning_assistant.generate.bias_analysis.find_biases_in_long_work as gblw\n",
    "    import image_captioning_assistant.generate.utils as gen_utils\n",
    "\n",
    "    # import image_captioning_assistant.data.data_classes as dc\n",
    "    import image_captioning_assistant.aws.s3 as s3_util\n",
    "finally:\n",
    "    os.chdir(\"../../projects/research\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for notebook\n",
    "def show_base64_image(encoded_str):\n",
    "    # Add padding if missing\n",
    "    missing_padding = len(encoded_str) % 4\n",
    "    if missing_padding:\n",
    "        encoded_str += \"=\" * (4 - missing_padding)\n",
    "\n",
    "    # Decode and display\n",
    "    image_data = base64.b64decode(encoded_str)\n",
    "    image = Image.open(BytesIO(image_data))\n",
    "    display(image)\n",
    "\n",
    "\n",
    "def download_s3_directory(bucket, s3_prefix, local_dir):\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    paginator = s3.get_paginator(\"list_objects_v2\")\n",
    "\n",
    "    for page in paginator.paginate(Bucket=bucket, Prefix=s3_prefix):\n",
    "        for obj in page.get(\"Contents\", []):\n",
    "            # Skip directory markers\n",
    "            if obj[\"Key\"].endswith(\"/\"):\n",
    "                continue\n",
    "\n",
    "            # Build local path\n",
    "            relative_path = obj[\"Key\"].replace(s3_prefix, \"\", 1)\n",
    "            local_path = local_dir / relative_path\n",
    "\n",
    "            # Create parent directories and download\n",
    "            local_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            s3.download_file(bucket, obj[\"Key\"], str(local_path))\n",
    "\n",
    "\n",
    "def display_bias(bias_list, attribute):\n",
    "    # Convert to DataFrame with multi-index\n",
    "    multi_index_data = []\n",
    "    for i, bias_dict in enumerate(bias_list):\n",
    "        for key, value in bias_dict.items():\n",
    "            multi_index_data.append(((i + 1, key), value))\n",
    "\n",
    "    # Create DataFrame\n",
    "    multi_index = pd.MultiIndex.from_tuples([item[0] for item in multi_index_data], names=[\"Bias ID\", \"Bias Item\"])\n",
    "    df = pd.DataFrame(\n",
    "        {f\"Output from AI Model for {attribute}\": [item[1] for item in multi_index_data]},\n",
    "        index=multi_index,\n",
    "    )\n",
    "    display(df)\n",
    "\n",
    "\n",
    "def print_output(output):\n",
    "    if \"description\" in output:\n",
    "        s = pd.Series(output)\n",
    "        display(pd.DataFrame({\"Metadata Item\": s.index, \"Output from AI Model\": s.values}))\n",
    "    else:\n",
    "        display_bias(output[\"metadata_biases\"][\"biases\"], \"Metadata\")\n",
    "        for i, bias_list in enumerate(output[\"page_biases\"]):\n",
    "            display_bias(bias_list[\"biases\"], f\"Page {i+1}\")\n",
    "\n",
    "\n",
    "def display_work_id_images(work_id):\n",
    "    \"\"\"\n",
    "    Display images for a work ID from S3, without saving to disk.\n",
    "    \"\"\"\n",
    "    # Get SHA1s for the work_id\n",
    "    shas = ground_truth_df[ground_truth_df[\"work_id\"] == work_id][\"page_sha1\"]\n",
    "    \n",
    "    # Create S3 URIs\n",
    "    image_s3_uris = [f\"s3://{bucket_name}/ground_truth_images/{sha}\" for sha in shas]\n",
    "    \n",
    "    # Load all images with no resizing\n",
    "    image_bytes_list = gen_utils.load_and_resize_images(\n",
    "        image_s3_uris=image_s3_uris,\n",
    "        s3_kwargs={},\n",
    "        resize_kwargs={}  # No resizing as requested\n",
    "    )\n",
    "    \n",
    "    # Display the images\n",
    "    from io import BytesIO\n",
    "    \n",
    "    for img_bytes in image_bytes_list:\n",
    "        if img_bytes is not None:\n",
    "            img = Image.open(BytesIO(img_bytes))\n",
    "            display(img)\n",
    "        else:\n",
    "            print(\"Failed to load image\")\n",
    "\n",
    "\n",
    "def gen_bias_for_wid(work_id, page_title, model_id=\"us.anthropic.claude-3-5-sonnet-20241022-v2:0\"):\n",
    "    image_path = \"ground_truth/images\"\n",
    "    shas = ground_truth_df[ground_truth_df[\"work_id\"] == work_id][[\"page_sha1\", \"page_title\"]]\n",
    "    image_s3_uris = []\n",
    "    if page_title.lower() == \"front\" and len(shas) > 1:\n",
    "        front_sha = shas[shas[\"page_title\"].str.lower() == \"front\"][\"page_sha1\"].values[0]\n",
    "        image_s3_uris.append(f\"s3://gaiic-emory-dev/ground_truth_images/{front_sha}\")\n",
    "        back_sha = shas[shas[\"page_title\"].str.lower() == \"back\"][\"page_sha1\"].values[0]\n",
    "        image_s3_uris.append(f\"s3://gaiic-emory-dev/ground_truth_images/{back_sha}\")\n",
    "    else:\n",
    "        front_sha = shas[shas[\"page_title\"] == page_title][\"page_sha1\"].values[0]\n",
    "        image_s3_uris.append(f\"s3://gaiic-emory-dev/ground_truth_images/{front_sha}\")\n",
    "        back_sha = None\n",
    "\n",
    "    s3_kwargs = {\n",
    "        \"config\": Config(\n",
    "            s3={\"addressing_style\": \"virtual\"},\n",
    "            signature_version=\"s3v4\",\n",
    "        ),\n",
    "        \"region_name\": \"us-east-1\",\n",
    "    }\n",
    "\n",
    "    llm_kwargs = {\n",
    "        # \"model\": \"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "        \"model_id\": model_id,\n",
    "    }\n",
    "\n",
    "    return gbsw.find_biases_in_short_work(\n",
    "        image_s3_uris,\n",
    "        s3_kwargs,\n",
    "        llm_kwargs,\n",
    "        {},\n",
    "        # work_context: str | None = None,\n",
    "        # original_metadata: str | None = None,\n",
    "    )\n",
    "\n",
    "\n",
    "def gen_bias_for_wid_long(work_id, model_id=\"us.anthropic.claude-3-5-sonnet-20241022-v2:0\"):\n",
    "    image_path = \"ground_truth/images\"\n",
    "    sha_df = ground_truth_df[ground_truth_df[\"work_id\"] == work_id][[\"page_sha1\", \"page_title\"]]\n",
    "    shas = list(sha_df[\"page_sha1\"].values)\n",
    "    image_page_names = list(sha_df[\"page_title\"].values)\n",
    "    image_s3_uris = [f\"s3://gaiic-emory-dev/ground_truth_images/{sha}\" for sha in shas]\n",
    "\n",
    "    s3_kwargs = {\n",
    "        \"config\": Config(\n",
    "            s3={\"addressing_style\": \"virtual\"},\n",
    "            signature_version=\"s3v4\",\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    llm_kwargs = {\n",
    "        # \"model\": \"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "        \"model_id\": model_id,\n",
    "        \"region_name\": \"us-east-1\",\n",
    "    }\n",
    "\n",
    "    return gblw.find_biases_in_long_work(\n",
    "        image_s3_uris,\n",
    "        s3_kwargs,\n",
    "        llm_kwargs,\n",
    "        {},\n",
    "        # work_context: str | None = None,\n",
    "        # original_metadata: str | None = None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download ground truth set to local\n",
    "\n",
    "# Configuration\n",
    "bucket_name = \"gaiic-emory-dev\"\n",
    "local_base = Path(\"ground_truth\")\n",
    "s3_client = boto3.client(\"s3\")\n",
    "\n",
    "# Download single CSV file\n",
    "csv_path = local_base / \"ground_truth.csv\"\n",
    "csv_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "s3_client.download_file(bucket_name, \"ground_truth.csv\", str(csv_path))\n",
    "ground_truth_df = pd.read_csv(\"ground_truth/ground_truth.csv\")\n",
    "\n",
    "# Download entire images directory -- slow, not required\n",
    "# download_s3_directory(\n",
    "#     bucket=bucket_name,\n",
    "#     s3_prefix='ground_truth_images/',\n",
    "#     local_dir=local_base / 'images'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL for diagnostics, dump out the WorkBiasAnalysis model schema, which is what is returned by the bias models\n",
    "# formatted_schema = json.dumps(dc.WorkBiasAnalysis.model_json_schema(), indent=4, ensure_ascii=True)\n",
    "# print(formatted_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a WID\n",
    "display_work_id_images(\"689d51c5f7-cor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the bias output and visualize it\n",
    "model_id = \"us.anthropic.claude-3-5-sonnet-20241022-v2:0\"\n",
    "# results = gen_bias_for_wid(\"880ht76hj7-cor\", \"Front\", model_id=model_id)  # cotton in sunny south 689d51c5f7-cor\n",
    "# results = gen_bias_for_wid(\"989r2280h5-cor\", \"Front\", model_id=model_id)  # Hatian mother with offspring\n",
    "results = gen_bias_for_wid(\"689d51c5f7-cor\", \"Front\", model_id=model_id)  # AA boy pointing at possum in tree\n",
    "# results = gen_bias_for_wid('24298sf7s0-cor', \"Front\", model_id=model_id)  # Burning of AA man\n",
    "# print(results.cot)\n",
    "print_output(results.model_dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the bias output and visualize it\n",
    "model_id = \"amazon.nova-pro-v1:0\"\n",
    "# results = gen_bias_for_wid(\"880ht76hj7-cor\", \"Front\", model_id=model_id)  # cotton in sunny south 689d51c5f7-cor\n",
    "# results = gen_bias_for_wid(\"989r2280h5-cor\", \"Front\", model_id=model_id)  # Hatian mother with offspring\n",
    "results = gen_bias_for_wid(\"689d51c5f7-cor\", \"Front\", model_id=model_id)  # AA boy pointing at possum in tree\n",
    "# results = gen_bias_for_wid('24298sf7s0-cor', \"Front\", model_id=model_id)  # Burning of AA man\n",
    "# print(results.cot)\n",
    "print_output(results.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run for longer works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_work_id_images(\"26663xsjkv-cor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"amazon.nova-pro-v1:0\"\n",
    "# response = gen_bias_for_wid_long('648ffbg7pg-cor') # 3 pages (high, none, low)\n",
    "response = gen_bias_for_wid_long(\"26663xsjkv-cor\", model_id=model_id)  # 4 pages (medium, high, none, none)\n",
    "print_output(response.model_dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"us.anthropic.claude-3-5-sonnet-20241022-v2:0\"\n",
    "# response = gen_bias_for_wid_long('648ffbg7pg-cor') # 3 pages (high, none, low)\n",
    "response = gen_bias_for_wid_long(\"26663xsjkv-cor\", model_id=model_id)  # 4 pages (medium, high, none, none)\n",
    "print_output(response.model_dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"us.meta.llama3-2-90b-instruct-v1:0\"\n",
    "# response = gen_bias_for_wid_long('648ffbg7pg-cor') # 3 pages (high, none, low)\n",
    "response = gen_bias_for_wid_long(\"26663xsjkv-cor\", model_id=model_id)  # 4 pages (medium, high, none, none)\n",
    "print_output(response.model_dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Evaluation -- NEEDS FIXING TO DEAL WITH DIFFERENCES BETWEEN GROUND TRUTH AND GENERATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.chdir(\"../../lib/src\")\n",
    "    import image_captioning_assistant.evaluate.evaluate_bias_analysis as eba\n",
    "    import image_captioning_assistant.evaluate.evaluate_structured_metadata as esm\n",
    "    import image_captioning_assistant.evaluate.evaluate_freeform_description as efd\n",
    "    from image_captioning_assistant.data.constants import BiasLevel, BiasType, LibraryFormat\n",
    "finally:\n",
    "    os.chdir(\"../../projects/research\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_bias_analysis = dc.BiasAnalysisEntry(\n",
    "    bias_type=BiasType.racial,\n",
    "    bias_level=BiasLevel.high,\n",
    "    explanation=\"Water fountain and a sign above it that says 'whites'\",\n",
    ")\n",
    "human_bias_analysis = dc.BiasAnalysisEntry(\n",
    "    bias_type=BiasType.racial,\n",
    "    bias_level=BiasLevel.high,\n",
    "    explanation=\"A water fountain and a sign above it tha reads 'whites'\",\n",
    ")\n",
    "\n",
    "potential_bias_evaluation = eba.evaluate_potential_biases(\n",
    "    llm_potential_biases=[llm_bias_analysis],\n",
    "    human_potential_biases=[human_bias_analysis],\n",
    "    chat_bedrock_converse_kwargs={\n",
    "        \"model\": \"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "        \"temperature\": 0.0,\n",
    "    },\n",
    ")\n",
    "potential_bias_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_bias_analysis = dc.BiasAnalysisEntry(\n",
    "    bias_type=BiasType.racial,\n",
    "    bias_level=BiasLevel.high,\n",
    "    explanation=\"Water fountain and a sign above it that says 'whites'\",\n",
    ")\n",
    "human_bias_analysis = dc.BiasAnalysisEntry(\n",
    "    bias_type=BiasType.age,\n",
    "    bias_level=BiasLevel.low,\n",
    "    explanation=\"Child Laborers are working in the fields.\",\n",
    ")\n",
    "\n",
    "potential_bias_evaluation = eba.evaluate_potential_biases(\n",
    "    llm_potential_biases=[llm_bias_analysis],\n",
    "    human_potential_biases=[human_bias_analysis],\n",
    "    chat_bedrock_converse_kwargs={\n",
    "        \"model\": \"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "        \"temperature\": 0.0,\n",
    "    },\n",
    ")\n",
    "potential_bias_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
