"""Evaluate the analysis of bias generated by an LLM."""

from typing import Any

from pydantic import BaseModel, Field

from image_captioning_assistant.data.data_classes import BiasAnalysis
from image_captioning_assistant.evaluate.evaluate_freeform_description import (
    FreeformResponseEvaluation,
    evaluate_freeform_response,
)


class BiasAnalysisEvaluation(BaseModel):
    """Evaluation of an LLM's bias analysis against that of a human."""

    bias_type_match: float = Field(
        ..., description="1 if bias types match, 0 if they don't"
    )
    bias_level_match: float = Field(
        ..., description="1 if bias levels match, 0 if they don't"
    )
    comments_evaluation: FreeformResponseEvaluation = Field(
        ..., description="Evaluation of bias comments"
    )


def evaluate_bias_analysis(
    llm_bias_analysis: BiasAnalysis,
    human_bias_analysis: BiasAnalysis,
    chat_bedrock_converse_kwargs: dict[str, Any],
) -> BiasAnalysisEvaluation:
    """Evaluate bias analysis

    Args:
        llm_bias_analysis (BiasAnalysis): Bias analysis generated by an LLM.
        human_bias_analysis (BiasAnalysis): Bias analysis generated by a human.
        chat_bedrock_converse_kwargs (dict[str, Any]): Keyword args for ChatBedrockConverse.

    Returns:
        BiasAnalysisEvaluation: _description_
    """
    comments_evaluation = evaluate_freeform_response(
        llm_freeform_response=llm_bias_analysis.comments,
        human_freeform_response=human_bias_analysis.comments,
        chat_bedrock_converse_kwargs=chat_bedrock_converse_kwargs,
    )
    return BiasAnalysisEvaluation(
        bias_type_match=int(
            llm_bias_analysis.bias_type == human_bias_analysis.bias_type
        ),
        bias_level_match=int(
            llm_bias_analysis.bias_level == human_bias_analysis.bias_level
        ),
        comments_evaluation=comments_evaluation,
    )
